{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdXNMz368T5O",
        "outputId": "d91ceb00-0d19-44f9-c917-8e966da84f89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import csv\n",
        "\n",
        "# Set the maximum field size allowed in CSV\n",
        "# to the maximum size supported by the system\n",
        "csv.field_size_limit(sys.maxsize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIRp9L2tTzNu",
        "outputId": "aec3f30c-fe8a-42ae-af4b-bde4675e5767"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131072"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Qao6nLtIDz5k"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Reading the 'zomato.csv' file\n",
        "df = pd.read_csv('/content/drive/MyDrive/zomato.csv',\n",
        "                 engine='python', on_bad_lines='skip', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping unnecessary columns\n",
        "df = df.drop(['url', 'phone', 'dish_liked', 'menu_item', 'listed_in(city)'], axis=1)\n",
        "\n",
        "# Renaming columns for better readability and consistency\n",
        "df = df.rename(columns={'approx_cost(for two people)':'cost',\n",
        "                        'listed_in(type)':'type'})\n",
        "\n",
        "# Capitalizing the first letter of each word in the 'name' column\n",
        "df.name = df.name.apply(lambda x:x.title())\n",
        "\n",
        "# Converting 'online_order' and 'book_table' columns to Boolean True/False\n",
        "df.online_order.replace(('Yes','No'),(True, False),inplace=True)\n",
        "df.book_table.replace(('Yes','No'),(True, False),inplace=True)\n",
        "\n",
        "# Cleaning and converting the 'cost' column to a float type\n",
        "df['cost'] = df['cost'].astype(str)\n",
        "df['cost'] = df['cost'].apply(lambda x: x.replace(',','.'))\n",
        "df['cost'] = df['cost'].astype(float)\n",
        "\n",
        "# Removing rows where 'rate' is 'NEW' or '-'\n",
        "df = df.loc[df.rate !='NEW']\n",
        "df = df.loc[df.rate !='-'].reset_index(drop=True)\n",
        "\n",
        "# Removing the '/5' part from the 'rate' column and converting it to float\n",
        "remove_slash = lambda x: x.replace('/5', '') if isinstance(x, str) else x\n",
        "df.rate = df.rate.apply(remove_slash).str.strip().astype('float')"
      ],
      "metadata": {
        "id": "M86SWr4DI8fQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### User-Based Collaborative Filtering Recommendations Using Cosine Similarity of Rating Patterns\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Counting the number of ratings in each 'reviews_list' entry\n",
        "array_sizes = df['reviews_list'].str.count(r'Rated \\d\\.\\d')\n",
        "\n",
        "# Filtering the DataFrame for restaurants\n",
        "# with 50 or more ratings (Assuming for scenario)\n",
        "df_filtered = df[array_sizes >= 50]\n",
        "\n",
        "# Extracting individual ratings and converting them to floats\n",
        "ratings_list = df_filtered['reviews_list'].str.findall(r'Rated (\\d\\.\\d)').explode().dropna()\n",
        "ratings_list = ratings_list.astype(float)\n",
        "\n",
        "# Creating an array of user IDs, with each ID repeated\n",
        "# according to the number of ratings they've given\n",
        "user_ids = np.repeat(np.arange(len(df_filtered)), df_filtered['reviews_list'].str.count(r'Rated \\d\\.\\d')).astype(int)\n",
        "\n",
        "# Limiting each user's ratings\n",
        "# to their first 50 reviews (Assuming for scenario)\n",
        "ratings_list = ratings_list.groupby(user_ids).head(50)\n",
        "user_ids = np.repeat(np.arange(len(df_filtered)), 50)\n",
        "\n",
        "# DF - user IDs, restaurant IDs, and ratings\n",
        "ratings_df = pd.DataFrame({\n",
        "    'user_id': user_ids,\n",
        "    'restaurant_id': np.tile(np.arange(len(df_filtered)), ratings_list.groupby(user_ids).size().max()),\n",
        "    'rating': ratings_list.values\n",
        "}).dropna()\n",
        "\n",
        "# Creating a pivot table for user-item (restaurant) interactions\n",
        "ratings_pivot = ratings_df.pivot_table(index='user_id', columns='restaurant_id', values='rating', fill_value=0)\n",
        "\n",
        "# Converting the pivot table into a sparse matrix\n",
        "ratings_matrix = csr_matrix(ratings_pivot.values)\n",
        "\n",
        "# Calculating the cosine similarity\n",
        "# between users based on their rating patterns\n",
        "user_similarity = cosine_similarity(ratings_matrix)"
      ],
      "metadata": {
        "id": "3vBPq5Gx_6YZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_fgHKRE7nrz",
        "outputId": "8f63df7f-5fcf-4695-b426-c0964cf7745c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6509, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "restaurant_names = df['name'].tolist()\n",
        "\n",
        "def recommend_items(user_id, user_similarity, ratings_pivot, top_n=5):\n",
        "    # Sorting other users based on similarity to the target user\n",
        "    # and excluding the target user itself\n",
        "    similar_users = user_similarity[user_id].argsort()[::-1]\n",
        "    similar_users = similar_users[1:]\n",
        "\n",
        "    # Predicting ratings for items by dot product of the similarity vector and the ratings matrix\n",
        "    recommendations = np.dot(user_similarity[user_id, :].reshape(1, -1), ratings_pivot.values).reshape(-1)\n",
        "\n",
        "    # Identifying items already rated by the user (don't need ~)\n",
        "    already_rated = np.nonzero(ratings_pivot.iloc[user_id].to_numpy())[0]\n",
        "\n",
        "    # Setting recommendations for already rated items to 0 to exclude them\n",
        "    recommendations[already_rated] = 0\n",
        "\n",
        "    # Getting top N recommendations, ignoring already rated items\n",
        "    recommendation_ids = recommendations.argsort()[::-1][:top_n]\n",
        "\n",
        "    # Converting restaurant indices to names\n",
        "    recommended_item_names = [restaurant_names[i] for i in recommendation_ids]\n",
        "\n",
        "    return recommended_item_names\n",
        "\n",
        "# Scenario: Recommending items for user with ID 0\n",
        "recommended_items = recommend_items(0, user_similarity, ratings_pivot)\n",
        "print(\"Recommended items for user 0:\", recommended_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh_Sp83oJ_lT",
        "outputId": "233c772d-ab4f-40c4-a2d9-51a0d3ada6d5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended items for user 0: ['Shree Cool Point', 'Corner House Ice Cream', 'Petoo', \"Pizza Baker'S\", 'Kanti Sweets']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Split the ratings data into training and testing sets\n",
        "train_data, test_data = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Pivot the training/testing data to create a user-item matrix\n",
        "train_data_pivot = train_data.pivot_table(index='user_id', columns='restaurant_id', values='rating', fill_value=0)\n",
        "test_data_pivot = test_data.pivot_table(index='user_id', columns='restaurant_id', values='rating', fill_value=0)\n",
        "\n",
        "# Convert the training data pivot table to a sparse matrix for efficiency\n",
        "train_ratings_matrix = csr_matrix(train_data_pivot.values)\n",
        "\n",
        "# Calculate the cosine similarity\n",
        "train_user_similarity = cosine_similarity(train_ratings_matrix)\n",
        "\n",
        "# predict user ratings based on user similarity and known ratings\n",
        "def predict_ratings(similarity, ratings):\n",
        "    mean_user_rating = ratings.mean(axis=1)\n",
        "    ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
        "    pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
        "    return pred\n",
        "\n",
        "# Predict ratings for all users in the training/test set\n",
        "user_prediction = predict_ratings(train_user_similarity, train_data_pivot.values)\n",
        "test_user_prediction = user_prediction[test_data_pivot.index, :][:, test_data_pivot.columns]\n",
        "\n",
        "test_data_pivot_array = test_data_pivot.values\n",
        "test_user_prediction_array = np.array(test_user_prediction)\n",
        "\n",
        "nonzero_indices = test_data_pivot_array.nonzero()\n",
        "\n",
        "# Calculate the root mean squared error (RMSE) of the predictions on the test set\n",
        "rmse = np.sqrt(mean_squared_error(test_data_pivot_array[nonzero_indices], test_user_prediction_array[nonzero_indices]))\n",
        "\n",
        "rmse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrQmRUJ59Vk5",
        "outputId": "1205c47e-438f-40e9-cd30-f156d0a7364c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.23030841174794"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}